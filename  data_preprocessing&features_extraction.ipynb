{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Image preprocessing aims at modifying the image in order to extract the representative features for training models\n",
    "#reference of method: http://francescopochetti.com/text-recognition-natural-scenes/#first\n",
    "#Computer font dataset from Chars74k dataset\n",
    "#source: http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/\n",
    "#Packages numpy and skimage required\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "from skimage import color\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "#read_images_fnt function read font character images in src file and extract the features through Histrogram of Oriented Gradient\n",
    "def read_images_fnt(path):\n",
    "\n",
    "    count=0\n",
    "    features=[]\n",
    "    for imagename in os.listdir(path):\n",
    "        #Change image from RGB color image to a grayscale image\n",
    "        image = color.rgb2gray(imread(path+\"/\"+imagename))\n",
    "        #Resize image to 32x32 pixel\n",
    "        imageResized = resize( image, (32,32) )\n",
    "        #Extract features through Histogram of Oriented Gradient and create a list of features\n",
    "        #reference: http://scikit-image.org/docs/dev/auto_examples/features_detection/plot_hog.html\n",
    "        #1. (optional) global image normalisation\n",
    "        #2. computing the gradient image in x and y\n",
    "        #3. computing gradient histograms\n",
    "        #4. normalising across blocks\n",
    "        #5. flattening into a feature vector\n",
    "        fd = hog(imageResized, cells_per_block=(1, 1))\n",
    "        features.append(fd.tolist())\n",
    "        count=count+1\n",
    "    return features,count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#62 classes including 0-9, A-Z and a-z\n",
    "list_of_label=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\n",
    "               \"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\",\n",
    "               \"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\"]\n",
    "#Dataset from English words generator\n",
    "#Preprocess training set of 13144 character font images from English words generator\n",
    "y_gen=[]\n",
    "for char in list_of_label:\n",
    "    y_gen.extend([char]*4)\n",
    "y_gen=y_gen*53\n",
    "X_gen=[]\n",
    "X_gen_new,temp=read_images_fnt(\"src/words_generated\")\n",
    "X_gen.extend(X_gen_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AndyTam\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "C:\\Users\\AndyTam\\Anaconda3\\lib\\site-packages\\skimage\\feature\\_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    }
   ],
   "source": [
    "#Packages numpy and skimage required\n",
    "import numpy as np\n",
    "\n",
    "from skimage.feature import hog\n",
    "from skimage import color, exposure\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.filters.rank import median\n",
    "from skimage.morphology import disk\n",
    "\n",
    "#read_images function read character images in src file and extract the features through Histrogram of Oriented Gradient\n",
    "def read_images(path,type,n):\n",
    "    features=[]\n",
    "    for i in range(1,n+1):\n",
    "        #Change image from RGB color image to a grayscale image\n",
    "        image = color.rgb2gray(imread(path+\"/\"+str(i)+\".\"+type))\n",
    "        #Apply median filter to denoise image\n",
    "        image_denoise=median(image, disk(2))\n",
    "        #Stretch contrast by rescaling intensity\n",
    "        p2, p98 = np.percentile(image_denoise, (2, 98))\n",
    "        image_contrast = exposure.rescale_intensity(image_denoise, in_range=(p2, p98))\n",
    "        #Resize image to 32x32 pixel\n",
    "        image_resized = resize( image_contrast, (32,32) )\n",
    "        #Extract features through Histogram of Oriented Gradient and create a list of features\n",
    "        #http://scikit-image.org/docs/dev/auto_examples/features_detection/plot_hog.html\n",
    "        fd = hog(image_resized, cells_per_block=(1, 1))\n",
    "        features.append(fd.tolist())\n",
    "    return features\n",
    "\n",
    "#Subset of street view images from Chars 74k dataset\n",
    "#source: https://www.kaggle.com/c/street-view-getting-started-with-julia/data\n",
    "#Preprocess training set of 6283 character images in street view\n",
    "X_char=[]\n",
    "X_char=read_images(\"src/train_char\",\"bmp\",6283)\n",
    "\n",
    "\n",
    "#Object Recognition dataset\n",
    "#source: https://www.kaggle.com/c/cifar-10/data\n",
    "#Preprocess training set of 14000 non-text object images\n",
    "X_obj=[]\n",
    "X_obj=read_images(\"src/train_obj\",\"png\",14000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#Save preprocessed features for training set of street view character and non-text object images\n",
    "with open(\"X_char.txt\", \"wb\") as X_file_w:   #Pickling\n",
    "       pickle.dump(X_char, X_file_w)\n",
    "with open(\"X_obj.txt\", \"wb\") as X_obj_file_w:   #Pickling\n",
    "       pickle.dump(X_obj, X_obj_file_w)\n",
    "with open(\"X_gen.txt\", \"wb\") as X_gen_file_w:   #Pickling\n",
    "       pickle.dump(X_gen, X_gen_file_w)\n",
    "with open(\"y_gen.txt\", \"wb\") as y_gen_file_w:   #Pickling\n",
    "       pickle.dump(y_gen, y_gen_file_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "#EMNIST handwritten character dataset\n",
    "#source: https://www.nist.gov/itl/iad/image-group/emnist-dataset\n",
    "#reference of reading the dataset: https://github.com/Coopss/EMNIST/blob/master/training.py\n",
    "#Load dataset in mat format\n",
    "mat = scipy.io.loadmat('src/emnist-byclass.mat')\n",
    "max_ = len(mat['dataset'][0][0][0][0][0][0])\n",
    "#Load images in 28x28 pixels\n",
    "training_images = mat['dataset'][0][0][0][0][0][0][:max_].reshape(max_, 28,28)\n",
    "training_labels = mat['dataset'][0][0][0][0][0][1][:max_].reshape(max_)\n",
    "y_hand=training_labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AndyTam\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "C:\\Users\\AndyTam\\Anaconda3\\lib\\site-packages\\skimage\\feature\\_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    }
   ],
   "source": [
    "#Package skimage required\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import hog\n",
    "from skimage import color\n",
    "training_images_resize=[]\n",
    "X_hand=[]\n",
    "for i in range(0,max_):\n",
    "    #Extract features through Histogram of Oriented Gradient and create a list of features\n",
    "    #http://scikit-image.org/docs/dev/auto_examples/features_detection/plot_hog.html\n",
    "    fd = hog(resize(training_images[i], (32,32) ), cells_per_block=(1, 1))\n",
    "    X_hand.append(fd.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save features for training set of handwritten character images\n",
    "with open(\"X_hand.txt\", \"wb\") as X_hand_file_w:   #Pickling\n",
    "       pickle.dump(X_hand, X_hand_file_w)\n",
    "with open(\"y_hand.txt\", \"wb\") as y_hand_file_w:   #Pickling\n",
    "       pickle.dump(y_hand, y_hand_file_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
